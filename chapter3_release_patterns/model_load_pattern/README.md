# model load pattern

## 目的

モデル・ロード・パターンでは推論サーバを配備する際、サーバイメージを Pull した後に推論サーバを起動し、その後にモデルファイルをロードして推論サーバを本稼働させます。モデルファイルのロード元を変数等で変更することによって、推論サーバで稼働するモデルを柔軟に変更することも可能です。

## 前提

- Python 3.8以上
- Docker
- Kubernetesクラスターまたはminikube

## 使い方

1. 推論用Dockerイメージおよびモデルロード用Dockerイメージのビルド
   
```sh
$ make build_all
```

2. 推論器とサイドカーをKubernetesクラスターにデプロイ

```sh
$ make deploy
```
